{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the effect values across all states and phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(df,data):\n",
    "    data = df[df.columns.drop('state')]\n",
    "    x = data.to_numpy()\n",
    "    min_ = np.min(x)\n",
    "    range_ = np.max(x) - np.min(x)\n",
    "    normalized = x - min_ /range_\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert p values to standard significance scales\n",
    "def significance_values(list_):\n",
    "    temp = []\n",
    "    for element in list_:\n",
    "        if element <= 0.001:\n",
    "            temp.append(\"***\")\n",
    "        elif element > 0.001 and element <= 0.01:\n",
    "            temp.append(\"**\")\n",
    "        elif element > 0.01 and element <= 0.05:\n",
    "            temp.append(\"*\")\n",
    "        else:\n",
    "            #incase the value is not significant\n",
    "            temp.append(\"no\")\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_plot(map_df, data_df, index, cmap, filename_,title,savedir='../../results/causal_impact/'):\n",
    "    merged_df = pd.merge(left=map_df[['state', 'geometry']], right=data_df, how='left', on='state')\n",
    "    merged_df.fillna(0,inplace=True)\n",
    "    merged_df['center'] = merged_df['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    merged_df['center'] = [coords[0] for coords in merged_df['center']]\n",
    "    merged_df['p_center'] = [(item[0],item[1]-0.8) for item in merged_df['center']]\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    merged_df.plot(column=index+' abs', cmap=cmap, linewidth=0.1, ax=ax, edgecolor='0.9', missing_kwds= dict(color = \"lightgrey\",))\n",
    "    ax.axis('off')\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap,norm=None)\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm)\n",
    "    \n",
    "    # Annotate state names and significance values\n",
    "    for idx, row in merged_df.iterrows():\n",
    "        phase = index.split(\" \")[1]\n",
    "#         print(phase)\n",
    "        pvalue_ = 'Phase '+str(phase)+' p'\n",
    "        if row['Phase '+str(phase)+' p']!=0 and row['Phase '+str(phase)+' p']!=\"no\":\n",
    "            plt.annotate(s=row[pvalue_], xy=row['p_center'], horizontalalignment='center', size=6, alpha=1)\n",
    "        plt.annotate(s=row['state'], xy=row['center'], horizontalalignment='center', size=6, alpha=1)\n",
    "    if title=='Rt':\n",
    "        plt.annotate(\"$R_t$ (Phase \"+str(phase)+\")\",xy=(88,29), horizontalalignment='center', size=10, alpha=0.9)\n",
    "    else:\n",
    "        plt.annotate(str(title)+\" (Phase \"+str(phase)+\")\",xy=(88,29), horizontalalignment='center', size=10, alpha=0.9)\n",
    "    fig.savefig(f'{savedir}/{index}_{filename_}.png', bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    #read the shape file\n",
    "    india_shp = 'maps/india/india.shp'\n",
    "    india_df = geopandas.read_file(india_shp)   \n",
    "    \n",
    "    #get consistent state names:\n",
    "    # Telangana?\n",
    "    mapper = {\n",
    "    'Andaman & Nicobar Island': 'Andaman and Nicobar Islands',\n",
    "    'Arunanchal Pradesh': 'Arunachal Pradesh',\n",
    "    'Dadara & Nagar Havelli': 'Dadra and Nagar Haveli',\n",
    "    'Daman & Diu': 'Daman and Diu',\n",
    "    'NCT of Delhi': 'Delhi',\n",
    "    'Jammu & Kashmir':'Jammu & Kashmir and Ladakh'\n",
    "    }\n",
    "    india_df['state'] = india_df['ST_NM'].apply(lambda x: mapper[x] if x in mapper.keys() else x)\n",
    "    \n",
    "    # read the data about the absolute causal effects obtained through causal impact\n",
    "    files_ = [\n",
    "        'case_growth_effects_6_25.csv',\n",
    "        'death_rate_effects_6_25.csv',\n",
    "        'mobility_effects_6_25.csv',\n",
    "        'rt_effects_6_25.csv'\n",
    "    ]\n",
    "    titles = ['Case Growth','Death Rate','Mobility','Rt']\n",
    "    cmaps  = ['Reds','Oranges','Blues','Greens']\n",
    "    directories = ['case_growth','death_rate','mobility','rt']\n",
    "    for index_ in range(0,len(files_)):\n",
    "        print(index_)\n",
    "        data = pd.read_csv('../../results/causal_impact/'+str(files_[index_]),index_col=0)\n",
    "        #separate lock and unlock phases\n",
    "        unlock_data = data[['state','Phase 5 abs','Phase 6 abs']]\n",
    "        lock_data = data[['state','Phase 1 abs','Phase 2 abs','Phase 3 abs','Phase 4 abs']]\n",
    "        \n",
    "        #obtain normalized data for lock period\n",
    "        data_lock_norm = min_max_scale(lock_data,data)\n",
    "        lock_data['Phase 1 abs'] = data_lock_norm[:,0]\n",
    "        lock_data['Phase 2 abs'] = data_lock_norm[:,1]\n",
    "        lock_data['Phase 3 abs'] = data_lock_norm[:,2]\n",
    "        lock_data['Phase 4 abs'] = data_lock_norm[:,3]\n",
    "\n",
    "        lock_data['Phase 1 p'] = data['Phase 1 p']\n",
    "        lock_data['Phase 2 p'] = data['Phase 2 p']\n",
    "        lock_data['Phase 3 p'] = data['Phase 3 p']\n",
    "        lock_data['Phase 4 p'] = data['Phase 4 p']\n",
    "\n",
    "        #obtain normalized data for unlock phase\n",
    "        data_unlock_norm = min_max_scale(unlock_data,data)\n",
    "        unlock_data['Phase 5 abs'] = data_unlock_norm[:,0]\n",
    "        unlock_data['Phase 6 abs'] = data_unlock_norm[:,1]\n",
    "\n",
    "        unlock_data['Phase 5 p'] = data['Phase 5 p']\n",
    "        unlock_data['Phase 6 p'] = data['Phase 6 p']\n",
    "        \n",
    "        \n",
    "        #convert p values to standard significant scale\n",
    "        lock_data['Phase 1 p'] = significance_values(list(lock_data['Phase 1 p'].astype(float)))\n",
    "        lock_data['Phase 2 p'] = significance_values(list(lock_data['Phase 2 p'].astype(float)))\n",
    "        lock_data['Phase 3 p'] = significance_values(list(lock_data['Phase 3 p'].astype(float)))\n",
    "        lock_data['Phase 4 p'] = significance_values(list(lock_data['Phase 4 p'].astype(float)))\n",
    "\n",
    "        unlock_data['Phase 5 p'] = significance_values(list(unlock_data['Phase 5 p'].astype(float)))\n",
    "        unlock_data['Phase 6 p'] = significance_values(list(unlock_data['Phase 6 p'].astype(float)))\n",
    "    \n",
    "        indices_lock = ['Phase 1','Phase 2','Phase 3','Phase 4']\n",
    "        for i in indices_lock:\n",
    "            map_plot(\n",
    "                india_df,\n",
    "                lock_data,\n",
    "                i, \n",
    "                cmap=cmaps[index_],\n",
    "                filename_ = titles[index_],\n",
    "                title=titles[index_],\n",
    "                savedir='../../results/causal_impact/'+str(directories[index_])\n",
    "            )\n",
    "\n",
    "        indices_unlock = ['Phase 5','Phase 6']\n",
    "        for i in indices_unlock:\n",
    "            map_plot(\n",
    "                india_df,\n",
    "                unlock_data,\n",
    "                i, \n",
    "                cmap=cmaps[index_],\n",
    "                filename_ = titles[index_],\n",
    "                title=titles[index_],\n",
    "                savedir='../../results/causal_impact/'+str(directories[index_])\n",
    "\n",
    "            )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
